{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0KOPesZ95nZF"
      },
      "outputs": [],
      "source": [
        "# Setup\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, cohen_kappa_score\n",
        "import google.generativeai as genai\n",
        "from openai import OpenAI\n",
        "from google.colab import files\n",
        "\n",
        "Llama_KEY = input(\"Paste your Llama API key: \").strip()\n",
        "GEMINI_KEY = input(\"Paste your Gemini API key: \").strip()\n",
        "\n",
        "os.environ[\"Llama_API_KEY\"] = Llama_KEY\n",
        "os.environ[\"GEMINI_API_KEY\"] = GEMINI_KEY\n",
        "\n",
        "# Initialize clients\n",
        "llama_client = OpenAI(\n",
        "    base_url=\"https://openrouter.ai/api/v1\",\n",
        "    api_key=os.environ[\"Llama_API_KEY\"]\n",
        ")\n",
        "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load dataset\n",
        "def load_dataset(file_path):\n",
        "    with open(file_path, \"r\") as f:\n",
        "        lines = [line.strip() for line in f if line.strip()]\n",
        "    return pd.DataFrame({\"raw_line\": lines})"
      ],
      "metadata": {
        "id": "ANhMtDa_5upZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Preprocessing\n",
        "def preprocess_text(df, text_column=\"raw_line\"):\n",
        "    speaker_turns = []\n",
        "    for line in df[text_column]:\n",
        "        line = str(line).strip()\n",
        "        if \":\" in line:\n",
        "            speaker, utterance = line.split(\":\", 1)\n",
        "            speaker_turns.append({\"speaker\": speaker.strip(), \"utterance\": utterance.strip()})\n",
        "        else:\n",
        "            speaker_turns.append({\"speaker\": \"Unknown\", \"utterance\": line})\n",
        "    return pd.DataFrame(speaker_turns)"
      ],
      "metadata": {
        "id": "YMP8Uumq6aXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trait information\n",
        "TRAIT_INFO = {\n",
        "    \"Expressive\": \"The speaker is open, shows a range of emotions, and readily shares thoughts and feelings.\",\n",
        "    \"Reserved\": \"The speaker is cautious, formal, and holds back on personal details.\",\n",
        "    \"Assertive\": \"The speaker is confident, direct, and takes the lead in the conversation.\",\n",
        "    \"Supportive\": \"The speaker is empathetic, agreeable, and focuses on building rapport.\",\n",
        "    \"Analytical\": \"The speaker is logical, fact-oriented, and structured in their responses.\",\n",
        "    \"Spontaneous\": \"The speaker is unpredictable, energetic, and frequently changes the topic or tone.\",\n",
        "    \"Neutral\": \"The speaker's trait is unclear or does not fit any of the other categories.\"\n",
        "}\n",
        "\n",
        "# 3. Human annotation loop (chunked)\n",
        "def human_annotation(df, rounds_per_chunk=1):\n",
        "    print(\"Trait explanations (refer to this before annotating):\\n\")\n",
        "    for trait, explanation in TRAIT_INFO.items():\n",
        "        print(f\"{trait}: {explanation}\")\n",
        "    print(\"\\n--- Starting annotation ---\\n\")\n",
        "\n",
        "    # Each round = 2 turns (Human1 + Human2)\n",
        "    chunk_size = rounds_per_chunk * 2\n",
        "    chunks = [df.iloc[i:i+chunk_size] for i in range(0, len(df), chunk_size)]\n",
        "    all_annotations = []\n",
        "\n",
        "    for idx, chunk in enumerate(chunks):\n",
        "        print(f\"\\n--- Chunk {idx+1} ---\\n\")\n",
        "        print(\"Chunk content:\")\n",
        "        for _, row in chunk.iterrows():\n",
        "            print(f\"{row['speaker']}: {row['utterance']}\")\n",
        "\n",
        "        chunk_annotations = {}\n",
        "        participants = chunk['speaker'].unique()\n",
        "        for participant in participants:\n",
        "            participant_turns = chunk[chunk['speaker'] == participant]['utterance'].tolist()\n",
        "            print(f\"\\nParticipant: {participant}\")\n",
        "            print(\"Their turns in this chunk:\")\n",
        "            for turn in participant_turns:\n",
        "                print(f\"- {turn}\")\n",
        "\n",
        "            print(\"Available traits: \" + \" | \".join(TRAIT_INFO.keys()))\n",
        "            choice = input(\"Enter trait for this participant in this chunk: \").strip().title()\n",
        "            if choice not in TRAIT_INFO:\n",
        "                choice = \"Neutral\"\n",
        "            chunk_annotations[participant] = choice\n",
        "        all_annotations.append(chunk_annotations)\n",
        "\n",
        "        next_chunk = input(\"Move to next chunk? (y/n): \").strip().lower()\n",
        "        if next_chunk != \"y\":\n",
        "            break\n",
        "\n",
        "    return all_annotations, chunks\n",
        "\n",
        "\n",
        "# Aggregate traits + distribution\n",
        "def aggregate_traits(chunk_annotations):\n",
        "  trait_counts = {}\n",
        "  for chunk in chunk_annotations:\n",
        "      for participant, trait in chunk.items():\n",
        "          if participant not in trait_counts:\n",
        "              trait_counts[participant] = {}\n",
        "          if trait not in trait_counts[participant]:\n",
        "              trait_counts[participant][trait] = 0\n",
        "          trait_counts[participant][trait] += 1\n",
        "\n",
        "  overall_traits = {}\n",
        "  for participant, counts in trait_counts.items():\n",
        "      overall_traits[participant] = max(counts, key=counts.get)\n",
        "\n",
        "  return overall_traits, trait_counts"
      ],
      "metadata": {
        "id": "LO7_vAUJ6beI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shared prompt builder\n",
        "def build_prompt(chunk):\n",
        "    chunk_text = \"\\n\".join([f\"{row['speaker']}: {row['utterance']}\" for _, row in chunk.iterrows()])\n",
        "    trait_list = \"\\n\".join([f\"{name}: {explanation}\" for name, explanation in TRAIT_INFO.items()])\n",
        "    prompt = f\"\"\"\n",
        "Analyze this conversation chunk and determine the conversational trait of each participant.\n",
        "Use only ONE trait per participant from the list below:\n",
        "\n",
        "{trait_list}\n",
        "\n",
        "Conversation chunk:\n",
        "{chunk_text}\n",
        "\n",
        "Respond with the traits as a dictionary, no further explanations, e.g.:\n",
        "{{\"Human 1\": \"Expressive\", \"Human 2\": \"Analytical\"}}\n",
        "\"\"\"\n",
        "    return prompt\n",
        "\n",
        "\n",
        "# Model annotation chunked\n",
        "def model_annotation(chunk, model_name=\"llama\"):\n",
        "    prompt = build_prompt(chunk)\n",
        "\n",
        "    if model_name == \"llama\":\n",
        "        response = llama_client.chat.completions.create(\n",
        "            model=\"meta-llama/llama-4-maverick:free\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0\n",
        "        )\n",
        "        text = response.choices[0].message.content.strip()\n",
        "\n",
        "    elif model_name == \"gemini\":\n",
        "        model = genai.GenerativeModel(\"gemini-2.5-flash-lite\")\n",
        "        response = model.generate_content(prompt)\n",
        "        text = response.text.strip()\n",
        "    else:\n",
        "        raise ValueError(\"Unknown model\")\n",
        "\n",
        "    # Convert model response to dict\n",
        "    try:\n",
        "        labels_dict = eval(text)\n",
        "    except:\n",
        "        labels_dict = {participant: \"Neutral\" for participant in chunk['speaker'].unique()}\n",
        "\n",
        "    return labels_dict"
      ],
      "metadata": {
        "id": "qQ8LSMVp6eAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Evaluation + Plot\n",
        "def evaluate_model(human_chunks, model_chunks, model_name):\n",
        "    human_flat = []\n",
        "    model_flat = []\n",
        "\n",
        "    for h_chunk, m_chunk in zip(human_chunks, model_chunks):\n",
        "        for participant in h_chunk.keys():\n",
        "            human_flat.append(h_chunk[participant])\n",
        "            model_flat.append(m_chunk.get(participant, \"Neutral\"))\n",
        "\n",
        "    acc = accuracy_score(human_flat, model_flat)\n",
        "    kappa = cohen_kappa_score(human_flat, model_flat)\n",
        "    print(f\"{model_name} - Accuracy: {acc:.2f}, Kappa: {kappa:.2f}\")\n",
        "    return acc, kappa\n",
        "\n",
        "def plot_results(results):\n",
        "    models = list(results.keys())\n",
        "    accs = [results[m][\"acc\"] for m in models]\n",
        "    kappas = [results[m][\"kappa\"] for m in models]\n",
        "\n",
        "    x = range(len(models))\n",
        "    plt.bar(x, accs, width=0.4, label=\"Accuracy\", align=\"center\")\n",
        "    plt.bar([p + 0.4 for p in x], kappas, width=0.4, label=\"Kappa\", align=\"center\")\n",
        "    plt.xticks([p + 0.2 for p in x], models)\n",
        "    plt.ylabel(\"Score\")\n",
        "    plt.title(\"Model vs Human Agreement\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Display chunk-wise comparison table with conversation text\n",
        "def display_chunk_comparison_with_text(prepared_chunks, human_chunks, llama_chunks, gemini_chunks):\n",
        "    rows = []\n",
        "\n",
        "    for idx, (chunk, h, l, g) in enumerate(zip(prepared_chunks, human_chunks, llama_chunks, gemini_chunks)):\n",
        "        participant_texts = {}\n",
        "        for participant in chunk['speaker'].unique():\n",
        "            participant_turns = chunk[chunk['speaker'] == participant]['utterance'].tolist()\n",
        "            participant_texts[participant] = \" | \".join(participant_turns)\n",
        "\n",
        "        for participant in h.keys():\n",
        "            rows.append({\n",
        "                \"Chunk\": idx+1,\n",
        "                \"Participant\": participant,\n",
        "                \"Conversation\": participant_texts.get(participant, \"\"),\n",
        "                \"Human\": h[participant],\n",
        "                \"Llama\": l.get(participant, \"Neutral\"),\n",
        "                \"Gemini\": g.get(participant, \"Neutral\")\n",
        "            })\n",
        "\n",
        "    df_comp = pd.DataFrame(rows)\n",
        "    print(\"\\n=== Chunk-wise Comparison Table with Text ===\")\n",
        "    pd.set_option('display.max_colwidth', None)\n",
        "    display(df_comp)\n",
        "    return df_comp\n",
        "\n",
        "# Plot trait distribution per participant (human + models)\n",
        "def plot_trait_distribution(human_chunks, llama_chunks, gemini_chunks):\n",
        "    participants = set()\n",
        "    for chunk in human_chunks:\n",
        "        participants.update(chunk.keys())\n",
        "    participants = sorted(participants)\n",
        "\n",
        "    fig, axes = plt.subplots(len(participants), 1, figsize=(8, 4*len(participants)))\n",
        "    if len(participants) == 1:\n",
        "        axes = [axes]\n",
        "\n",
        "    for ax, participant in zip(axes, participants):\n",
        "        # Collect trait counts\n",
        "        human_counts = {}\n",
        "        llama_counts = {}\n",
        "        gemini_counts = {}\n",
        "\n",
        "        for chunk in human_chunks:\n",
        "            if participant in chunk:\n",
        "                human_counts[chunk[participant]] = human_counts.get(chunk[participant], 0) + 1\n",
        "        for chunk in llama_chunks:\n",
        "            if participant in chunk:\n",
        "                llama_counts[chunk[participant]] = llama_counts.get(chunk[participant], 0) + 1\n",
        "        for chunk in gemini_chunks:\n",
        "            if participant in chunk:\n",
        "                gemini_counts[chunk[participant]] = gemini_counts.get(chunk[participant], 0) + 1\n",
        "\n",
        "        all_traits = sorted(set(list(human_counts.keys()) + list(llama_counts.keys()) + list(gemini_counts.keys())))\n",
        "        x = range(len(all_traits))\n",
        "        ax.bar([p - 0.2 for p in x], [human_counts.get(tr,0) for tr in all_traits], width=0.2, label=\"Human\")\n",
        "        ax.bar(x, [llama_counts.get(tr,0) for tr in all_traits], width=0.2, label=\"Llama\")\n",
        "        ax.bar([p + 0.2 for p in x], [gemini_counts.get(tr,0) for tr in all_traits], width=0.2, label=\"Gemini\")\n",
        "        ax.set_xticks(x)\n",
        "        ax.set_xticklabels(all_traits)\n",
        "        ax.set_ylabel(\"Count\")\n",
        "        ax.set_title(f\"Trait Distribution - {participant}\")\n",
        "        ax.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "vnN4gmLc7O0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Run pipeline\n",
        "DATASET_FILENAME = \"human_chat.txt\"\n",
        "if not os.path.exists(DATASET_FILENAME):\n",
        "    uploaded = files.upload()\n",
        "\n",
        "df_raw = load_dataset(DATASET_FILENAME)\n",
        "df_turns = preprocess_text(df_raw)\n",
        "\n",
        "rounds_per_chunk = 4  # adjust as needed\n",
        "chunk_size = rounds_per_chunk * 2\n",
        "chunks = [df_turns.iloc[i:i+chunk_size] for i in range(0, len(df_turns), chunk_size)]\n",
        "\n",
        "all_human_chunks = []\n",
        "all_llama_chunks = []\n",
        "all_gemini_chunks = []\n",
        "prepared_chunks = []  # keep track for display\n",
        "\n",
        "print(\"Trait explanations (refer to this before annotating):\\n\")\n",
        "for trait, explanation in TRAIT_INFO.items():\n",
        "    print(f\"{trait}: {explanation}\")\n",
        "print(\"\\n--- Starting annotation ---\\n\")\n",
        "\n",
        "for idx, chunk in enumerate(chunks):\n",
        "    print(f\"\\n--- Chunk {idx+1} ---\\n\")\n",
        "    for _, row in chunk.iterrows():\n",
        "        print(f\"{row['speaker']}: {row['utterance']}\")\n",
        "\n",
        "    chunk_annotations = {}\n",
        "    participants = chunk['speaker'].unique()\n",
        "    for participant in participants:\n",
        "        participant_turns = chunk[chunk['speaker'] == participant]['utterance'].tolist()\n",
        "        print(f\"\\nParticipant: {participant}\")\n",
        "        print(\"Their turns in this chunk:\")\n",
        "        for turn in participant_turns:\n",
        "            print(f\"- {turn}\")\n",
        "        print(\"Available traits: \" + \" | \".join(TRAIT_INFO.keys()))\n",
        "        choice = input(\"Enter trait for this participant in this chunk: \").strip().title()\n",
        "        if choice not in TRAIT_INFO:\n",
        "            choice = \"Neutral\"\n",
        "        chunk_annotations[participant] = choice\n",
        "\n",
        "    all_human_chunks.append(chunk_annotations)\n",
        "    prepared_chunks.append(chunk)  # store for comparison display\n",
        "\n",
        "    # Model annotation immediately\n",
        "    llama_labels = model_annotation(chunk, model_name=\"llama\")\n",
        "    gemini_labels = model_annotation(chunk, model_name=\"gemini\")\n",
        "    all_llama_chunks.append(llama_labels)\n",
        "    all_gemini_chunks.append(gemini_labels)\n",
        "\n",
        "    # Stop condition\n",
        "    if idx == len(chunks)-1:  # last chunk\n",
        "        print(\"Reached the last chunk.\")\n",
        "        break\n",
        "    next_chunk = input(\"Move to next chunk? (y/n): \").strip().lower()\n",
        "    if next_chunk != \"y\":\n",
        "        print(\"Stopping annotation as requested by user.\")\n",
        "        break\n",
        "\n",
        "# Aggregate human traits\n",
        "overall_traits, trait_distribution = aggregate_traits(all_human_chunks)\n",
        "\n",
        "# Evaluate\n",
        "results = {}\n",
        "acc, kappa = evaluate_model(all_human_chunks, all_llama_chunks, \"Llama\")\n",
        "results[\"Llama\"] = {\"acc\": acc, \"kappa\": kappa}\n",
        "acc, kappa = evaluate_model(all_human_chunks, all_gemini_chunks, \"Gemini\")\n",
        "results[\"Gemini\"] = {\"acc\": acc, \"kappa\": kappa}\n",
        "\n",
        "plot_results(results)\n",
        "\n",
        "# Display overall trait distribution\n",
        "print(\"\\n=== Overall Traits per Participant ===\")\n",
        "for participant, trait in overall_traits.items():\n",
        "    print(f\"{participant}: {trait}\")\n",
        "\n",
        "print(\"\\n=== Trait Distribution by Participant ===\")\n",
        "for participant, counts in trait_distribution.items():\n",
        "    print(f\"{participant}: {counts}\")\n",
        "\n",
        "# Display chunk-wise comparison table\n",
        "df_chunk_comparison = display_chunk_comparison_with_text(\n",
        "    prepared_chunks, all_human_chunks, all_llama_chunks, all_gemini_chunks\n",
        ")\n",
        "\n",
        "# Plot trait distribution per participant (human + models)\n",
        "plot_trait_distribution(all_human_chunks, all_llama_chunks, all_gemini_chunks)"
      ],
      "metadata": {
        "id": "ixkVXStL7S5X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}